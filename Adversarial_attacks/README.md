# Adversarial Attacks on Deep Learning Models
## Deep Learning Project 3 - Spring 2025

This repository contains the implementation of adversarial attacks on image classifiers, specifically targeting a ResNet-34 model trained on the ImageNet-1K dataset.

## Project Overview

The goal of this project is to develop and evaluate various adversarial attack strategies that can degrade the performance of deep learning image classifiers. We implement:

1. Fast Gradient Sign Method (FGSM) attacks
2. Advanced adversarial attacks
3. Patch attacks
4. Transferability analysis 
