{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7694b3e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:37.713181Z",
     "iopub.status.busy": "2025-03-12T04:42:37.712926Z",
     "iopub.status.idle": "2025-03-12T04:42:39.083100Z",
     "shell.execute_reply": "2025-03-12T04:42:39.082094Z"
    },
    "papermill": {
     "duration": 1.378472,
     "end_time": "2025-03-12T04:42:39.084581",
     "exception": false,
     "start_time": "2025-03-12T04:42:37.706109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n",
      "/kaggle/input/nearlyfinal/pytorch/default/1/best_model (9).pth\n",
      "/kaggle/input/finetuning_latest_90/pytorch/default/1/best_model (11).pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8883d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:39.097083Z",
     "iopub.status.busy": "2025-03-12T04:42:39.096704Z",
     "iopub.status.idle": "2025-03-12T04:42:57.442814Z",
     "shell.execute_reply": "2025-03-12T04:42:57.442076Z"
    },
    "papermill": {
     "duration": 18.353834,
     "end_time": "2025-03-12T04:42:57.444471",
     "exception": false,
     "start_time": "2025-03-12T04:42:39.090637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "!pip install torchsummary\n",
    "import torchsummary\n",
    "import random\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.nn.utils import (\n",
    "  parameters_to_vector as Params2Vec,\n",
    "  vector_to_parameters as Vec2Params\n",
    ")\n",
    "\n",
    "import torchvision.transforms.v2 as v2\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9285fa66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:57.457194Z",
     "iopub.status.busy": "2025-03-12T04:42:57.456830Z",
     "iopub.status.idle": "2025-03-12T04:42:57.459830Z",
     "shell.execute_reply": "2025-03-12T04:42:57.459161Z"
    },
    "papermill": {
     "duration": 0.010646,
     "end_time": "2025-03-12T04:42:57.461174",
     "exception": false,
     "start_time": "2025-03-12T04:42:57.450528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "data_dir = \"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c4b74c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:57.473378Z",
     "iopub.status.busy": "2025-03-12T04:42:57.473136Z",
     "iopub.status.idle": "2025-03-12T04:42:57.476489Z",
     "shell.execute_reply": "2025-03-12T04:42:57.475828Z"
    },
    "papermill": {
     "duration": 0.010768,
     "end_time": "2025-03-12T04:42:57.477749",
     "exception": false,
     "start_time": "2025-03-12T04:42:57.466981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to unpickle a batch\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031a4ffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:57.489363Z",
     "iopub.status.busy": "2025-03-12T04:42:57.489105Z",
     "iopub.status.idle": "2025-03-12T04:42:57.496545Z",
     "shell.execute_reply": "2025-03-12T04:42:57.495949Z"
    },
    "papermill": {
     "duration": 0.014648,
     "end_time": "2025-03-12T04:42:57.497742",
     "exception": false,
     "start_time": "2025-03-12T04:42:57.483094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class labels from batches.meta\n",
    "meta_path = os.path.join(data_dir, \"batches.meta\")\n",
    "meta_data = unpickle(meta_path)\n",
    "class_labels = [label.decode('utf-8') for label in meta_data[b'label_names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7eb445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:57.509078Z",
     "iopub.status.busy": "2025-03-12T04:42:57.508881Z",
     "iopub.status.idle": "2025-03-12T04:42:57.511813Z",
     "shell.execute_reply": "2025-03-12T04:42:57.511177Z"
    },
    "papermill": {
     "duration": 0.009736,
     "end_time": "2025-03-12T04:42:57.512980",
     "exception": false,
     "start_time": "2025-03-12T04:42:57.503244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and merge Training & Test Data\n",
    "X_train_test, y_train_test = [], []\n",
    "ids_train_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a23b41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:42:57.524181Z",
     "iopub.status.busy": "2025-03-12T04:42:57.523978Z",
     "iopub.status.idle": "2025-03-12T04:43:00.242470Z",
     "shell.execute_reply": "2025-03-12T04:43:00.241592Z"
    },
    "papermill": {
     "duration": 2.725598,
     "end_time": "2025-03-12T04:43:00.243870",
     "exception": false,
     "start_time": "2025-03-12T04:42:57.518272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (60000, 32, 32, 3) (60000,)\n",
      "Class distribution: {0: 6000, 1: 6000, 2: 6000, 3: 6000, 4: 6000, 5: 6000, 6: 6000, 7: 6000, 8: 6000, 9: 6000}\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data (All 5 Batches) and Test Data in a single loop\n",
    "for i in range(1, 7):  # 1 to 6 (including test batch as 6th iteration)\n",
    "    batch_name = f\"data_batch_{i}\" if i <= 5 else \"test_batch\"\n",
    "    batch_path = os.path.join(data_dir, batch_name)\n",
    "    batch_data = unpickle(batch_path)\n",
    "    \n",
    "    images = batch_data[b'data']\n",
    "    labels = batch_data[b'labels']\n",
    "\n",
    "    filenames = batch_data[b'filenames']\n",
    "\n",
    "    # Decode filenames from bytes to strings\n",
    "    filenames = [name.decode('utf-8') for name in filenames]\n",
    "    \n",
    "    # Reshape images to (num_samples, 32, 32, 3)\n",
    "    images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    \n",
    "    X_train_test.append(images)\n",
    "    y_train_test.extend(labels)\n",
    "    ids_train_test.extend(filenames)  # Store filenames as IDs\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train_test = np.concatenate(X_train_test, axis=0)\n",
    "y_train_test = np.array(y_train_test)\n",
    "ids_train_test = np.array(ids_train_test)  # Convert IDs to NumPy array\n",
    "\n",
    "# Compute merged dataset class distribution\n",
    "unique_classes, counts_classes = np.unique(y_train_test, return_counts=True)\n",
    "\n",
    "print(\"Merged dataset shape:\", X_train_test.shape, y_train_test.shape)\n",
    "print(\"Class distribution:\", dict(zip(unique_classes, counts_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36191425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.255879Z",
     "iopub.status.busy": "2025-03-12T04:43:00.255630Z",
     "iopub.status.idle": "2025-03-12T04:43:00.259847Z",
     "shell.execute_reply": "2025-03-12T04:43:00.259246Z"
    },
    "papermill": {
     "duration": 0.011444,
     "end_time": "2025-03-12T04:43:00.261046",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.249602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class with Transformations\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform_structured):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform_structured = transform_structured\n",
    "        \n",
    "        # self.transform_natural = transform_natural\n",
    "\n",
    "        # CIFAR-10 Structured & Natural Classes\n",
    "        #self.structured_classes = {0, 1, 8, 9}  # Airplane, Car, Ship, Truck\n",
    "        #self.natural_classes = {2, 3, 4, 5, 6, 7}  # Bird, Cat, Deer, Dog, Frog, Horse\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply appropriate transformation\n",
    "        #if label in self.structured_classes:\n",
    "        #     image = self.transform_structured(image)\n",
    "        #else:\n",
    "        #     image = self.transform_natural(image)\n",
    "        image = self.transform_structured(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cd03fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.272745Z",
     "iopub.status.busy": "2025-03-12T04:43:00.272493Z",
     "iopub.status.idle": "2025-03-12T04:43:00.277539Z",
     "shell.execute_reply": "2025-03-12T04:43:00.276793Z"
    },
    "papermill": {
     "duration": 0.01233,
     "end_time": "2025-03-12T04:43:00.278823",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.266493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cutout(torch.nn.Module):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_size (int): The size of the square cutout mask.\n",
    "            p (float): Probability of applying cutout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        # img is a torch.Tensor with shape (C, H, W)\n",
    "        if random.random() > self.p:\n",
    "            return img  # No cutout applied\n",
    "        \n",
    "        c, h, w = img.shape\n",
    "        # Choose random center coordinates\n",
    "        y = random.randint(0, h - 1)\n",
    "        x = random.randint(0, w - 1)\n",
    "        \n",
    "        y1 = max(0, y - self.mask_size // 2)\n",
    "        y2 = min(h, y + self.mask_size // 2)\n",
    "        x1 = max(0, x - self.mask_size // 2)\n",
    "        x2 = min(w, x + self.mask_size // 2)\n",
    "        \n",
    "        # Zero out the selected region\n",
    "        img[:, y1:y2, x1:x2] = 0.0\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ec2beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.300716Z",
     "iopub.status.busy": "2025-03-12T04:43:00.300493Z",
     "iopub.status.idle": "2025-03-12T04:43:00.305122Z",
     "shell.execute_reply": "2025-03-12T04:43:00.304392Z"
    },
    "papermill": {
     "duration": 0.011503,
     "end_time": "2025-03-12T04:43:00.306308",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.294805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_finetune = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Positional Augmentations (Helps Generalization)\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(p=0.5),  \n",
    "    transforms.RandomRotation(5),  \n",
    "\n",
    "    # Mild Color Augmentation (Avoid Over-Augmenting)\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05),  \n",
    "\n",
    "    # Reduce Background Dependence\n",
    "    transforms.RandomErasing(p=0.2),  \n",
    "    Cutout(mask_size=12, p=0.3),  \n",
    "\n",
    "    # Normalization \n",
    "    transforms.Normalize(mean=[0.49139968, 0.48215827, 0.44653124],  \n",
    "                         std=[0.24703233, 0.24348505, 0.26158768])  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61c27443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.345508Z",
     "iopub.status.busy": "2025-03-12T04:43:00.345294Z",
     "iopub.status.idle": "2025-03-12T04:43:00.348894Z",
     "shell.execute_reply": "2025-03-12T04:43:00.348140Z"
    },
    "papermill": {
     "duration": 0.010707,
     "end_time": "2025-03-12T04:43:00.350083",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.339376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64 # Same as training\n",
    "num_workers = 4  # Kaggle: use 2 if needed\n",
    "\n",
    "# Create dataset with different transformations for different classes\n",
    "train_dataset = CIFAR10Dataset(X_train_test, y_train_test, transform_finetune)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356155ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.361682Z",
     "iopub.status.busy": "2025-03-12T04:43:00.361472Z",
     "iopub.status.idle": "2025-03-12T04:43:00.372872Z",
     "shell.execute_reply": "2025-03-12T04:43:00.372170Z"
    },
    "papermill": {
     "duration": 0.018382,
     "end_time": "2025-03-12T04:43:00.373987",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.355605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom ResNet Model\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, 1).view(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out).view(x.size(0), x.size(1), 1, 1)\n",
    "        return x * out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64 \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.seblock = SEBlock(channels=self.in_planes)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)  \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)  \n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.seblock(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16b75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:00.385116Z",
     "iopub.status.busy": "2025-03-12T04:43:00.384921Z",
     "iopub.status.idle": "2025-03-12T04:43:01.153224Z",
     "shell.execute_reply": "2025-03-12T04:43:01.152491Z"
    },
    "papermill": {
     "duration": 0.775607,
     "end_time": "2025-03-12T04:43:01.154837",
     "exception": false,
     "start_time": "2025-03-12T04:43:00.379230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-e13ec4cedda8>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))  # Load weights\n"
     ]
    }
   ],
   "source": [
    "epochs = 30 # Finetune for 30 epoch\n",
    "\n",
    "def LiteResNet():\n",
    "    return ResNet(BasicBlock, [7, 4, 3])  \n",
    "\n",
    "# Define Training and Evaluation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LiteResNet().to(device)\n",
    "\n",
    "model_path = \"/kaggle/input/finetuning_latest_90/pytorch/default/1/best_model.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))  # Load weights\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fine-Tuning Phase Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b39e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:01.167388Z",
     "iopub.status.busy": "2025-03-12T04:43:01.167119Z",
     "iopub.status.idle": "2025-03-12T04:43:01.170734Z",
     "shell.execute_reply": "2025-03-12T04:43:01.170083Z"
    },
    "papermill": {
     "duration": 0.011026,
     "end_time": "2025-03-12T04:43:01.171988",
     "exception": false,
     "start_time": "2025-03-12T04:43:01.160962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze first few layers so that the model keeps general features & previous training knowledge\n",
    "for param in model.conv1.parameters():\n",
    "    param.requires_grad = False  # Freeze only the first layer\n",
    "\n",
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad = False  # Freeze the first block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7943e369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:01.183704Z",
     "iopub.status.busy": "2025-03-12T04:43:01.183504Z",
     "iopub.status.idle": "2025-03-12T04:43:02.629671Z",
     "shell.execute_reply": "2025-03-12T04:43:02.628571Z"
    },
    "papermill": {
     "duration": 1.45352,
     "end_time": "2025-03-12T04:43:02.631079",
     "exception": false,
     "start_time": "2025-03-12T04:43:01.177559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Linear-3                    [-1, 4]             256\n",
      "              ReLU-4                    [-1, 4]               0\n",
      "            Linear-5                   [-1, 64]             256\n",
      "           Sigmoid-6                   [-1, 64]               0\n",
      "           SEBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
      "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
      "           Conv2d-25           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-26           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-27           [-1, 64, 32, 32]               0\n",
      "           Conv2d-28           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 32, 32]             128\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-34           [-1, 64, 32, 32]             128\n",
      "           Conv2d-35           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-36           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-37           [-1, 64, 32, 32]               0\n",
      "           Conv2d-38           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-39           [-1, 64, 32, 32]             128\n",
      "           Conv2d-40           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-44          [-1, 128, 16, 16]             256\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "           Conv2d-47          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-48          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-49          [-1, 128, 16, 16]               0\n",
      "           Conv2d-50          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-56          [-1, 128, 16, 16]             256\n",
      "           Conv2d-57          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-58          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-59          [-1, 128, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 16, 16]             256\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-70            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-76            [-1, 256, 8, 8]               0\n",
      "           Conv2d-77            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-78            [-1, 256, 8, 8]             512\n",
      "           Conv2d-79            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-81            [-1, 256, 8, 8]               0\n",
      "        AvgPool2d-82            [-1, 256, 1, 1]               0\n",
      "           Linear-83                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,919,626\n",
      "Trainable params: 4,400,010\n",
      "Non-trainable params: 519,616\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.63\n",
      "Params size (MB): 18.77\n",
      "Estimated Total Size (MB): 45.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965c9111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:02.644268Z",
     "iopub.status.busy": "2025-03-12T04:43:02.644028Z",
     "iopub.status.idle": "2025-03-12T04:43:02.670085Z",
     "shell.execute_reply": "2025-03-12T04:43:02.669525Z"
    },
    "papermill": {
     "duration": 0.033901,
     "end_time": "2025-03-12T04:43:02.671190",
     "exception": false,
     "start_time": "2025-03-12T04:43:02.637289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mixup = v2.MixUp(alpha=1.0, num_classes=10)  # 🔥 Use PyTorch’s built-in MixUp\n",
    "cutmix = v2.CutMix(alpha=1.0, num_classes=10)\n",
    "mixup = v2.MixUp(alpha=0.4, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66090df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:02.694132Z",
     "iopub.status.busy": "2025-03-12T04:43:02.693932Z",
     "iopub.status.idle": "2025-03-12T04:43:02.699651Z",
     "shell.execute_reply": "2025-03-12T04:43:02.699053Z"
    },
    "papermill": {
     "duration": 0.013089,
     "end_time": "2025-03-12T04:43:02.700810",
     "exception": false,
     "start_time": "2025-03-12T04:43:02.687721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply cutmix and mixup to the batch\n",
    "EXCLUDE_CLASSES = [3, 5]  # 3: Cat, 5: Dog\n",
    "\n",
    "def apply_augmentation(images, labels):\n",
    "    batch_size = images.shape[0]\n",
    "    rand_vals = torch.rand(batch_size, device=labels.device)  # Ensure random values are on the same device\n",
    "\n",
    "    cutmix_mask = rand_vals < 0.35  # Apply 35% CutMix\n",
    "    mixup_mask = (rand_vals >= 0.35) & (rand_vals < 0.7)  # Apply 35% MixUp\n",
    "\n",
    "    # Move exclude_mask to the correct device\n",
    "    exclude_mask = torch.tensor([label.item() in EXCLUDE_CLASSES for label in labels], \n",
    "                                dtype=torch.bool, device=labels.device)\n",
    "\n",
    "    # Ensure Cats & Dogs are NOT used in MixUp or CutMix\n",
    "    cutmix_mask &= ~exclude_mask  # Remove Cats & Dogs from CutMix\n",
    "    mixup_mask &= ~exclude_mask   # Remove Cats & Dogs from MixUp\n",
    "\n",
    "    # Apply augmentations\n",
    "    if cutmix_mask.any():\n",
    "        aug_images, aug_labels = cutmix(images[cutmix_mask], labels[cutmix_mask])\n",
    "        images[cutmix_mask] = aug_images\n",
    "        labels[cutmix_mask] = aug_labels.argmax(dim=1)  # Convert back to class indices\n",
    "\n",
    "    if mixup_mask.any():\n",
    "        aug_images, aug_labels = mixup(images[mixup_mask], labels[mixup_mask])\n",
    "        images[mixup_mask] = aug_images\n",
    "        labels[mixup_mask] = aug_labels.argmax(dim=1)  # Convert back to class indices\n",
    "\n",
    "    return images, labels  # 30% remain unchanged, and excluded classes are untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29af99b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:02.712562Z",
     "iopub.status.busy": "2025-03-12T04:43:02.712351Z",
     "iopub.status.idle": "2025-03-12T04:43:02.716412Z",
     "shell.execute_reply": "2025-03-12T04:43:02.715696Z"
    },
    "papermill": {
     "duration": 0.011144,
     "end_time": "2025-03-12T04:43:02.717604",
     "exception": false,
     "start_time": "2025-03-12T04:43:02.706460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-89d76f2976db>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Store training history\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "epoch_list = []\n",
    "\n",
    "# Initialize best loss and accuracy tracking\n",
    "best_loss = float(\"inf\")\n",
    "best_accuracy = 0.0\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf403e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T04:43:02.729280Z",
     "iopub.status.busy": "2025-03-12T04:43:02.729055Z",
     "iopub.status.idle": "2025-03-12T05:05:17.092606Z",
     "shell.execute_reply": "2025-03-12T05:05:17.090839Z"
    },
    "papermill": {
     "duration": 1334.376673,
     "end_time": "2025-03-12T05:05:17.099840",
     "exception": false,
     "start_time": "2025-03-12T04:43:02.723167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-2d0bb3d02cc2>:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model at epoch 0 with loss 0.3028 and accuracy 90.97%\n",
      "Epoch 0, Train loss 0.3028, Train Accuracy 90.97%\n",
      "Epoch 1, Train loss 0.3099, Train Accuracy 90.71%\n",
      "Epoch 2, Train loss 0.3064, Train Accuracy 90.70%\n",
      "Epoch 3, Train loss 0.3020, Train Accuracy 90.83%\n",
      "Epoch 4, Train loss 0.3077, Train Accuracy 90.59%\n",
      "Epoch 5, Train loss 0.3059, Train Accuracy 90.49%\n",
      "Saved best model at epoch 6 with loss 0.2935 and accuracy 90.97%\n",
      "Epoch 6, Train loss 0.2935, Train Accuracy 90.97%\n",
      "Epoch 7, Train loss 0.2996, Train Accuracy 90.81%\n",
      "Epoch 8, Train loss 0.2895, Train Accuracy 90.97%\n",
      "Epoch 9, Train loss 0.2960, Train Accuracy 90.85%\n",
      "Epoch 10, Train loss 0.2954, Train Accuracy 90.85%\n",
      "Epoch 11, Train loss 0.2981, Train Accuracy 90.81%\n",
      "Epoch 12, Train loss 0.2926, Train Accuracy 90.91%\n",
      "Saved best model at epoch 13 with loss 0.2780 and accuracy 91.35%\n",
      "Epoch 13, Train loss 0.2780, Train Accuracy 91.35%\n",
      "Epoch 14, Train loss 0.2944, Train Accuracy 90.86%\n",
      "Epoch 15, Train loss 0.2951, Train Accuracy 90.85%\n",
      "Epoch 16, Train loss 0.2863, Train Accuracy 91.16%\n",
      "Saved best model at epoch 17 with loss 0.2781 and accuracy 91.37%\n",
      "Epoch 17, Train loss 0.2781, Train Accuracy 91.37%\n",
      "Epoch 18, Train loss 0.2909, Train Accuracy 91.07%\n",
      "Epoch 19, Train loss 0.2806, Train Accuracy 91.20%\n",
      "Epoch 20, Train loss 0.2894, Train Accuracy 91.00%\n",
      "Epoch 21, Train loss 0.2865, Train Accuracy 91.24%\n",
      "Epoch 22, Train loss 0.2944, Train Accuracy 90.90%\n",
      "Epoch 23, Train loss 0.2810, Train Accuracy 91.13%\n",
      "Epoch 24, Train loss 0.2970, Train Accuracy 90.75%\n",
      "Epoch 25, Train loss 0.2862, Train Accuracy 91.07%\n",
      "Epoch 26, Train loss 0.2807, Train Accuracy 91.22%\n",
      "Epoch 27, Train loss 0.2894, Train Accuracy 90.97%\n",
      "Epoch 28, Train loss 0.2873, Train Accuracy 91.13%\n",
      "Epoch 29, Train loss 0.2845, Train Accuracy 91.12%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Apply MixUp or CutMix randomly with defined probabilities\n",
    "        images, labels = apply_augmentation(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predicted_output = model(images)\n",
    "            fit = loss(predicted_output, labels)  # Compute loss\n",
    "        \n",
    "        scaler.scale(fit).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += fit.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        if labels.dim() == 2:  # If labels are one-hot encoded (MixUp or CutMix)\n",
    "            labels = labels.argmax(dim=1)  # Convert to class indices\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = predicted_output.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    train_accuracy = 100. * train_correct / train_total\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model based on loss & accuracy\n",
    "    if best_accuracy < train_accuracy:\n",
    "        best_accuracy = train_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model_finetuned.pth\")\n",
    "        print(f\"Saved best model at epoch {epoch} with loss {train_loss:.4f} and accuracy {best_accuracy:.2f}%\")\n",
    "        \n",
    "    # Store loss and accuracy history\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Train loss {train_loss:.4f}, Train Accuracy {train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4beb30f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:17.115334Z",
     "iopub.status.busy": "2025-03-12T05:05:17.115027Z",
     "iopub.status.idle": "2025-03-12T05:05:17.129420Z",
     "shell.execute_reply": "2025-03-12T05:05:17.128613Z"
    },
    "papermill": {
     "duration": 0.023461,
     "end_time": "2025-03-12T05:05:17.130667",
     "exception": false,
     "start_time": "2025-03-12T05:05:17.107206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save training history to Excel\n",
    "history_df = pd.DataFrame({\n",
    "    'Epoch': epoch,\n",
    "    'Train Loss': train_loss_history,\n",
    "    'Train Accuracy': train_accuracy_history\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212a6113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:17.145105Z",
     "iopub.status.busy": "2025-03-12T05:05:17.144858Z",
     "iopub.status.idle": "2025-03-12T05:05:17.914482Z",
     "shell.execute_reply": "2025-03-12T05:05:17.913471Z"
    },
    "papermill": {
     "duration": 0.778316,
     "end_time": "2025-03-12T05:05:17.915950",
     "exception": false,
     "start_time": "2025-03-12T05:05:17.137634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history while finetuning saved to training_history_finetuning.xlsx\n"
     ]
    }
   ],
   "source": [
    "history_df.to_excel(\"training_history_finetuning.xlsx\", index=False)\n",
    "print(\"Training history while finetuning saved to training_history_finetuning.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b9efa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:17.931430Z",
     "iopub.status.busy": "2025-03-12T05:05:17.931036Z",
     "iopub.status.idle": "2025-03-12T05:05:54.301045Z",
     "shell.execute_reply": "2025-03-12T05:05:54.300134Z"
    },
    "papermill": {
     "duration": 36.37941,
     "end_time": "2025-03-12T05:05:54.302733",
     "exception": false,
     "start_time": "2025-03-12T05:05:17.923323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch  # Unpacking correctly\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Model predictions\n",
    "        outputs = model(inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1)\n",
    "        confidence_score = torch.max(probabilities, dim=1).values\n",
    "\n",
    "        # Append results\n",
    "        for i in range(len(labels)):\n",
    "            results.append({\n",
    "                \"score\": predicted_class[i].item(),\n",
    "                \"confidence_score\": confidence_score[i].item(),\n",
    "                \"actual_label\": labels[i].item(),\n",
    "                \"correct\": predicted_class[i].item() == labels[i].item()\n",
    "            })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c43ed74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:54.319303Z",
     "iopub.status.busy": "2025-03-12T05:05:54.319004Z",
     "iopub.status.idle": "2025-03-12T05:05:54.384656Z",
     "shell.execute_reply": "2025-03-12T05:05:54.383792Z"
    },
    "papermill": {
     "duration": 0.075233,
     "end_time": "2025-03-12T05:05:54.385972",
     "exception": false,
     "start_time": "2025-03-12T05:05:54.310739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.997787</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.955720</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.880871</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.991098</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>7</td>\n",
       "      <td>0.978534</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>8</td>\n",
       "      <td>0.997890</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>4</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>5</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996291</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  confidence_score  actual_label  correct\n",
       "0          7          0.997787             7     True\n",
       "1          3          0.998816             3     True\n",
       "2          1          0.955720             1     True\n",
       "3          2          0.880871             2     True\n",
       "4          8          0.991098             8     True\n",
       "...      ...               ...           ...      ...\n",
       "59995      7          0.978534             7     True\n",
       "59996      8          0.997890             8     True\n",
       "59997      4          0.996656             4     True\n",
       "59998      5          0.987169             5     True\n",
       "59999      0          0.996291             0     True\n",
       "\n",
       "[60000 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cb96682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:54.403224Z",
     "iopub.status.busy": "2025-03-12T05:05:54.402974Z",
     "iopub.status.idle": "2025-03-12T05:05:54.407996Z",
     "shell.execute_reply": "2025-03-12T05:05:54.407309Z"
    },
    "papermill": {
     "duration": 0.014631,
     "end_time": "2025-03-12T05:05:54.409350",
     "exception": false,
     "start_time": "2025-03-12T05:05:54.394719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6068\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows where score is exactly 7\n",
    "count = (df['score'] == 6).sum()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01279be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:54.425335Z",
     "iopub.status.busy": "2025-03-12T05:05:54.425087Z",
     "iopub.status.idle": "2025-03-12T05:05:54.434981Z",
     "shell.execute_reply": "2025-03-12T05:05:54.434294Z"
    },
    "papermill": {
     "duration": 0.019152,
     "end_time": "2025-03-12T05:05:54.436179",
     "exception": false,
     "start_time": "2025-03-12T05:05:54.417027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>0.476076</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0.495429</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4</td>\n",
       "      <td>0.465143</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2</td>\n",
       "      <td>0.288377</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>5</td>\n",
       "      <td>0.446734</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59343</th>\n",
       "      <td>9</td>\n",
       "      <td>0.494389</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59456</th>\n",
       "      <td>2</td>\n",
       "      <td>0.365543</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59459</th>\n",
       "      <td>6</td>\n",
       "      <td>0.394464</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59625</th>\n",
       "      <td>8</td>\n",
       "      <td>0.482890</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59681</th>\n",
       "      <td>2</td>\n",
       "      <td>0.444213</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  confidence_score  actual_label  correct\n",
       "82         2          0.476076             4    False\n",
       "163        0          0.495429             0     True\n",
       "250        4          0.465143             7    False\n",
       "404        2          0.288377             3    False\n",
       "561        5          0.446734             3    False\n",
       "...      ...               ...           ...      ...\n",
       "59343      9          0.494389             0    False\n",
       "59456      2          0.365543             4    False\n",
       "59459      6          0.394464             2    False\n",
       "59625      8          0.482890             8     True\n",
       "59681      2          0.444213             2     True\n",
       "\n",
       "[548 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where confidence score is less than 50%\n",
    "df_low_confidence = df[df[\"confidence_score\"] < 0.50]\n",
    "df_low_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c05cbc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T05:05:54.452616Z",
     "iopub.status.busy": "2025-03-12T05:05:54.452401Z",
     "iopub.status.idle": "2025-03-12T05:05:54.595244Z",
     "shell.execute_reply": "2025-03-12T05:05:54.594467Z"
    },
    "papermill": {
     "duration": 0.152584,
     "end_time": "2025-03-12T05:05:54.596705",
     "exception": false,
     "start_time": "2025-03-12T05:05:54.444121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>correct_predictions</th>\n",
       "      <th>false_predictions</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0(airplane)</td>\n",
       "      <td>5914</td>\n",
       "      <td>86</td>\n",
       "      <td>5914</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1(automobile)</td>\n",
       "      <td>5940</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>5940</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2(bird)</td>\n",
       "      <td>5844</td>\n",
       "      <td>156</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>5844</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3(cat)</td>\n",
       "      <td>5717</td>\n",
       "      <td>283</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>5717</td>\n",
       "      <td>35</td>\n",
       "      <td>106</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4(deer)</td>\n",
       "      <td>5883</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>5883</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5(dog)</td>\n",
       "      <td>5757</td>\n",
       "      <td>243</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>42</td>\n",
       "      <td>5757</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6(frog)</td>\n",
       "      <td>5933</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>5933</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7(horse)</td>\n",
       "      <td>5929</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5929</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8(ship)</td>\n",
       "      <td>5937</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5937</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9(truck)</td>\n",
       "      <td>5919</td>\n",
       "      <td>81</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label  correct_predictions  false_predictions  pred_0  pred_1  \\\n",
       "0    0(airplane)                 5914                 86    5914       9   \n",
       "1  1(automobile)                 5940                 60       4    5940   \n",
       "2        2(bird)                 5844                156      37       0   \n",
       "3         3(cat)                 5717                283       6       1   \n",
       "4        4(deer)                 5883                117       5       0   \n",
       "5         5(dog)                 5757                243       8       1   \n",
       "6        6(frog)                 5933                 67       6       2   \n",
       "7       7(horse)                 5929                 71       7       0   \n",
       "8        8(ship)                 5937                 63      25       9   \n",
       "9       9(truck)                 5919                 81      10      43   \n",
       "\n",
       "   pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  pred_8  pred_9  \n",
       "0      14       4       3       2       1       6      35      12  \n",
       "1       3       3       0       0       1       1       8      40  \n",
       "2    5844      18      41      15      29       7       9       0  \n",
       "3      49    5717      35     106      49      23      11       3  \n",
       "4      26      14    5883      13      30      25       3       1  \n",
       "5      32     122      42    5757      15      21       1       1  \n",
       "6      19      14      17       5    5933       2       2       0  \n",
       "7      15       8      19      14       2    5929       5       1  \n",
       "8       5       5       4       1       3       1    5937      10  \n",
       "9       3       1       1       0       5       2      16    5919  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table for counting wrong predictions\n",
    "\n",
    "prediction_counts = df.groupby([\"actual_label\", \"score\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Rename prediction columns\n",
    "prediction_counts.columns = [f\"pred_{int(col)}\" for col in prediction_counts.columns]\n",
    "\n",
    "# Group by actual label and count correct/incorrect predictions\n",
    "summary_df = df.groupby(\"actual_label\").agg(\n",
    "    correct_predictions=(\"correct\", \"sum\"),   # Sum of True values (Correct predictions)\n",
    "    false_predictions=(\"correct\", lambda x: (~x).sum())  # Sum of False values (Incorrect predictions)\n",
    ").reset_index()\n",
    "\n",
    "# Merge prediction counts into summary_df\n",
    "summary_df = summary_df.merge(prediction_counts, left_on=\"actual_label\", right_index=True, how=\"left\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary_df.rename(columns={\"actual_label\": \"Label\"}, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 (in case a label was never predicted as a certain class)\n",
    "summary_df.fillna(0, inplace=True)\n",
    "\n",
    "# Map numerical labels to class names in the format \"0(aeroplane)\", \"1(automobile)\", etc.\n",
    "label_map = {i: f\"{i}({class_labels[i]})\" for i in range(len(class_labels))}\n",
    "\n",
    "# Apply mapping to the 'Label' column\n",
    "summary_df[\"Label\"] = summary_df[\"Label\"].map(label_map)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814e071",
   "metadata": {
    "papermill": {
     "duration": 0.009109,
     "end_time": "2025-03-12T05:05:54.614121",
     "exception": false,
     "start_time": "2025-03-12T05:05:54.605012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 263477,
     "modelInstanceId": 241825,
     "sourceId": 282237,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 264013,
     "modelInstanceId": 242395,
     "sourceId": 282880,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1403.975088,
   "end_time": "2025-03-12T05:05:58.082290",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-12T04:42:34.107202",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
