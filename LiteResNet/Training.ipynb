{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7e2245",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.674113,
     "end_time": "2025-03-11T17:12:50.571019",
     "exception": false,
     "start_time": "2025-03-11T17:12:49.896906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cb5915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:50.582743Z",
     "iopub.status.busy": "2025-03-11T17:12:50.582405Z",
     "iopub.status.idle": "2025-03-11T17:12:57.943851Z",
     "shell.execute_reply": "2025-03-11T17:12:57.943173Z"
    },
    "papermill": {
     "duration": 7.368537,
     "end_time": "2025-03-11T17:12:57.945486",
     "exception": false,
     "start_time": "2025-03-11T17:12:50.576949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.nn.utils import (\n",
    "  parameters_to_vector as Params2Vec,\n",
    "  vector_to_parameters as Vec2Params\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import torchvision.transforms.v2 as v2\n",
    "import random\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a75474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:57.956243Z",
     "iopub.status.busy": "2025-03-11T17:12:57.955880Z",
     "iopub.status.idle": "2025-03-11T17:12:57.958707Z",
     "shell.execute_reply": "2025-03-11T17:12:57.958143Z"
    },
    "papermill": {
     "duration": 0.00931,
     "end_time": "2025-03-11T17:12:57.959799",
     "exception": false,
     "start_time": "2025-03-11T17:12:57.950489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "data_dir = \"/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a4965b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:57.969607Z",
     "iopub.status.busy": "2025-03-11T17:12:57.969402Z",
     "iopub.status.idle": "2025-03-11T17:12:57.972464Z",
     "shell.execute_reply": "2025-03-11T17:12:57.971869Z"
    },
    "papermill": {
     "duration": 0.00909,
     "end_time": "2025-03-11T17:12:57.973559",
     "exception": false,
     "start_time": "2025-03-11T17:12:57.964469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to unpickle a batch\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11fe2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:57.983375Z",
     "iopub.status.busy": "2025-03-11T17:12:57.983157Z",
     "iopub.status.idle": "2025-03-11T17:12:59.584971Z",
     "shell.execute_reply": "2025-03-11T17:12:59.584031Z"
    },
    "papermill": {
     "duration": 1.608498,
     "end_time": "2025-03-11T17:12:59.586602",
     "exception": false,
     "start_time": "2025-03-11T17:12:57.978104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Training Data (All 5 Batches)\n",
    "X_train, y_train = [], []\n",
    "for i in range(1, 6):  # Loop through data_batch_1 to data_batch_5\n",
    "    batch_path = os.path.join(data_dir, f\"data_batch_{i}\")\n",
    "    batch_data = unpickle(batch_path)\n",
    "    \n",
    "    images = batch_data[b'data']\n",
    "    labels = batch_data[b'labels']\n",
    "\n",
    "    # Reshape images to (num_samples, 32, 32, 3)\n",
    "    images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    X_train.append(images)\n",
    "    y_train.extend(labels)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73d9bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.597750Z",
     "iopub.status.busy": "2025-03-11T17:12:59.597509Z",
     "iopub.status.idle": "2025-03-11T17:12:59.862704Z",
     "shell.execute_reply": "2025-03-11T17:12:59.861789Z"
    },
    "papermill": {
     "duration": 0.272359,
     "end_time": "2025-03-11T17:12:59.864159",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.591800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Test Data\n",
    "test_path = os.path.join(data_dir, \"test_batch\")\n",
    "test_data = unpickle(test_path)\n",
    "\n",
    "X_test = test_data[b'data']\n",
    "y_test = np.array(test_data[b'labels'])\n",
    "\n",
    "# Reshape images to (num_samples, 32, 32, 3)\n",
    "X_test = X_test.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952ffd37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.874756Z",
     "iopub.status.busy": "2025-03-11T17:12:59.874511Z",
     "iopub.status.idle": "2025-03-11T17:12:59.878872Z",
     "shell.execute_reply": "2025-03-11T17:12:59.878119Z"
    },
    "papermill": {
     "duration": 0.010828,
     "end_time": "2025-03-11T17:12:59.880200",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.869372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class with Transformations for train dataset\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform_structured):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform_structured = transform_structured\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = self.transform_structured(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df88c89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.890085Z",
     "iopub.status.busy": "2025-03-11T17:12:59.889850Z",
     "iopub.status.idle": "2025-03-11T17:12:59.893853Z",
     "shell.execute_reply": "2025-03-11T17:12:59.893122Z"
    },
    "papermill": {
     "duration": 0.010225,
     "end_time": "2025-03-11T17:12:59.894992",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.884767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Dataset Class with Transformations for validation dataset\n",
    "class CIFAR10ValDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply the same transformation to all validation images (no augmentation)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbbaf0c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.904687Z",
     "iopub.status.busy": "2025-03-11T17:12:59.904495Z",
     "iopub.status.idle": "2025-03-11T17:12:59.909529Z",
     "shell.execute_reply": "2025-03-11T17:12:59.908747Z"
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2025-03-11T17:12:59.910674",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.899573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cutout(torch.nn.Module):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_size (int): The size of the square cutout mask.\n",
    "            p (float): Probability of applying cutout.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        # img is a torch.Tensor with shape (C, H, W)\n",
    "        if random.random() > self.p:\n",
    "            return img  # No cutout applied\n",
    "        \n",
    "        c, h, w = img.shape\n",
    "        # Choose random center coordinates\n",
    "        y = random.randint(0, h - 1)\n",
    "        x = random.randint(0, w - 1)\n",
    "        \n",
    "        y1 = max(0, y - self.mask_size // 2)\n",
    "        y2 = min(h, y + self.mask_size // 2)\n",
    "        x1 = max(0, x - self.mask_size // 2)\n",
    "        x2 = min(w, x + self.mask_size // 2)\n",
    "        \n",
    "        # Zero out the selected region\n",
    "        img[:, y1:y2, x1:x2] = 0.0\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52aee946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.921107Z",
     "iopub.status.busy": "2025-03-11T17:12:59.920889Z",
     "iopub.status.idle": "2025-03-11T17:12:59.927780Z",
     "shell.execute_reply": "2025-03-11T17:12:59.927236Z"
    },
    "papermill": {
     "duration": 0.013312,
     "end_time": "2025-03-11T17:12:59.928908",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.915596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_weak_edges(image, threshold=50):\n",
    "    \"\"\"\n",
    "    Detect weak edges using Sobel filters in PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor (C, H, W).\n",
    "        threshold (int): Edge strength threshold to determine weak edges.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if edges are weak, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert RGB to grayscale using ITU-R BT.601 standard\n",
    "    grayscale = 0.299 * image[0] + 0.587 * image[1] + 0.114 * image[2]  # Shape: (H, W)\n",
    "\n",
    "    # Apply Sobel filters for edge detection\n",
    "    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(image.device)\n",
    "    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(image.device)\n",
    "\n",
    "    # Reshape grayscale to (1, 1, H, W) for convolution\n",
    "    grayscale = grayscale.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
    "\n",
    "    # Apply Sobel convolution\n",
    "    edge_x = F.conv2d(grayscale, sobel_x, padding=1)\n",
    "    edge_y = F.conv2d(grayscale, sobel_y, padding=1)\n",
    "    \n",
    "    # Compute edge strength\n",
    "    edges = torch.sqrt(edge_x ** 2 + edge_y ** 2)  # Edge magnitude\n",
    "    edge_sum = edges.sum().item()  # Sum of edge intensities\n",
    "\n",
    "    return edge_sum < threshold  # Return True if edges are weak\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"\n",
    "    Enhance image contrast using PyTorch's histogram equalization.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor (C, H, W).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Contrast-enhanced image tensor (C, H, W).\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for histogram equalization\n",
    "    grayscale = 0.299 * image[0] + 0.587 * image[1] + 0.114 * image[2]  # Shape: (H, W)\n",
    "\n",
    "    # Compute histogram and cumulative distribution function (CDF)\n",
    "    hist = torch.histc(grayscale, bins=256, min=0.0, max=1.0)\n",
    "    cdf = hist.cumsum(0) / hist.sum()  # Normalize CDF\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    equalized = torch.index_select(cdf, 0, (grayscale * 255).long().clamp(0, 255))  # Apply equalization\n",
    "    equalized = equalized / equalized.max()  # Normalize\n",
    "\n",
    "    # Scale RGB channels based on equalized grayscale\n",
    "    enhanced_image = image * (equalized / (grayscale + 1e-6))  # Avoid division by zero\n",
    "    enhanced_image = torch.clamp(enhanced_image, 0, 1)  # Ensure valid range\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "class ContrastEnhancementTransform(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom PyTorch transform to selectively enhance contrast for weak edge images.\n",
    "    \"\"\"\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Apply contrast enhancement selectively based on weak edge detection.\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor): Input image tensor (C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Transformed image tensor (C, H, W).\n",
    "        \"\"\"\n",
    "        if detect_weak_edges(img):  # Apply only to weak edge images\n",
    "            img = enhance_contrast(img)\n",
    "\n",
    "        return img  # No conversion needed (still a PyTorch tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b88103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.938496Z",
     "iopub.status.busy": "2025-03-11T17:12:59.938296Z",
     "iopub.status.idle": "2025-03-11T17:12:59.942905Z",
     "shell.execute_reply": "2025-03-11T17:12:59.942309Z"
    },
    "papermill": {
     "duration": 0.010628,
     "end_time": "2025-03-11T17:12:59.944052",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.933424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformation for CIFAR Training\n",
    "transform_structured = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ContrastEnhancementTransform(),  # Selectively enhance weak-edge images\n",
    "\n",
    "    # Position-based augmentations (important for generalization)\n",
    "    transforms.RandomCrop(32, padding=4),  # Simulates different framing\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Prevents left-right bias\n",
    "    transforms.RandomVerticalFlip(p=0.2),  # Rare but useful for certain classes\n",
    "    transforms.RandomRotation(5),  # Small rotation to keep features intact\n",
    "\n",
    "    # Mild Color Augmentation (Avoid Over-Augmenting)\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Less aggressive\n",
    "\n",
    "    # Avoid over-relying on background contrast\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), \n",
    "    transforms.RandomErasing(p=0.2),  # Mild occlusion\n",
    "    Cutout(mask_size=12, p=0.5),  # Forces the model to learn object features\n",
    "\n",
    "    # Normalization based on CIFAR statistics\n",
    "    transforms.Normalize(mean=[0.49139968, 0.48215827, 0.44653124], \n",
    "                         std=[0.24703233, 0.24348505, 0.26158768])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59c5782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.977824Z",
     "iopub.status.busy": "2025-03-11T17:12:59.977632Z",
     "iopub.status.idle": "2025-03-11T17:12:59.980772Z",
     "shell.execute_reply": "2025-03-11T17:12:59.980184Z"
    },
    "papermill": {
     "duration": 0.009214,
     "end_time": "2025-03-11T17:12:59.981935",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.972721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformation for CIFAR Validation set\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # No randomness, just conversion\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], \n",
    "                         std=[0.247, 0.243, 0.261])  # Normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d376db59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:59.991628Z",
     "iopub.status.busy": "2025-03-11T17:12:59.991427Z",
     "iopub.status.idle": "2025-03-11T17:12:59.995730Z",
     "shell.execute_reply": "2025-03-11T17:12:59.994879Z"
    },
    "papermill": {
     "duration": 0.010403,
     "end_time": "2025-03-11T17:12:59.996928",
     "exception": false,
     "start_time": "2025-03-11T17:12:59.986525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64  \n",
    "num_workers = 4  # Kaggle: use 2 if needed\n",
    "\n",
    "# Create dataset with different transformations for different classes\n",
    "train_dataset = CIFAR10Dataset(X_train, y_train, transform_structured)\n",
    "test_dataset = CIFAR10ValDataset(X_test, y_test, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "132da137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:00.007114Z",
     "iopub.status.busy": "2025-03-11T17:13:00.006863Z",
     "iopub.status.idle": "2025-03-11T17:13:00.012212Z",
     "shell.execute_reply": "2025-03-11T17:13:00.011397Z"
    },
    "papermill": {
     "duration": 0.011624,
     "end_time": "2025-03-11T17:13:00.013413",
     "exception": false,
     "start_time": "2025-03-11T17:13:00.001789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Squeeze-and-Excitation Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.adaptive_avg_pool2d(x, 1).view(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out).view(x.size(0), x.size(1), 1, 1)\n",
    "        return x * out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e242c60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:00.023600Z",
     "iopub.status.busy": "2025-03-11T17:13:00.023372Z",
     "iopub.status.idle": "2025-03-11T17:13:00.032837Z",
     "shell.execute_reply": "2025-03-11T17:13:00.032011Z"
    },
    "papermill": {
     "duration": 0.015795,
     "end_time": "2025-03-11T17:13:00.033969",
     "exception": false,
     "start_time": "2025-03-11T17:13:00.018174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom ResNet Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64 \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.seblock = SEBlock(channels=self.in_planes)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)  \n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)  \n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.seblock(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bea99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:00.044166Z",
     "iopub.status.busy": "2025-03-11T17:13:00.043907Z",
     "iopub.status.idle": "2025-03-11T17:13:00.414192Z",
     "shell.execute_reply": "2025-03-11T17:13:00.413341Z"
    },
    "papermill": {
     "duration": 0.376841,
     "end_time": "2025-03-11T17:13:00.415551",
     "exception": false,
     "start_time": "2025-03-11T17:13:00.038710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (seblock): SEBlock(\n",
       "    (fc1): Linear(in_features=64, out_features=4, bias=False)\n",
       "    (fc2): Linear(in_features=4, out_features=64, bias=False)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 125\n",
    "\n",
    "def LiteResNet():\n",
    "    return ResNet(BasicBlock, [7, 4, 3])  \n",
    "\n",
    "# Define Training and Evaluation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LiteResNet().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Phase\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b696b904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:00.426147Z",
     "iopub.status.busy": "2025-03-11T17:13:00.425889Z",
     "iopub.status.idle": "2025-03-11T17:13:01.109226Z",
     "shell.execute_reply": "2025-03-11T17:13:01.107831Z"
    },
    "papermill": {
     "duration": 0.690174,
     "end_time": "2025-03-11T17:13:01.110755",
     "exception": false,
     "start_time": "2025-03-11T17:13:00.420581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Linear-3                    [-1, 4]             256\n",
      "              ReLU-4                    [-1, 4]               0\n",
      "            Linear-5                   [-1, 64]             256\n",
      "           Sigmoid-6                   [-1, 64]               0\n",
      "           SEBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
      "           Conv2d-18           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 32, 32]             128\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 32, 32]             128\n",
      "           Conv2d-25           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-26           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-27           [-1, 64, 32, 32]               0\n",
      "           Conv2d-28           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 32, 32]             128\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-34           [-1, 64, 32, 32]             128\n",
      "           Conv2d-35           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-36           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-37           [-1, 64, 32, 32]               0\n",
      "           Conv2d-38           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-39           [-1, 64, 32, 32]             128\n",
      "           Conv2d-40           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-44          [-1, 128, 16, 16]             256\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "           Conv2d-47          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-48          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-49          [-1, 128, 16, 16]               0\n",
      "           Conv2d-50          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 16, 16]             256\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-56          [-1, 128, 16, 16]             256\n",
      "           Conv2d-57          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-58          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-59          [-1, 128, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 16, 16]             256\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-70            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-76            [-1, 256, 8, 8]               0\n",
      "           Conv2d-77            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-78            [-1, 256, 8, 8]             512\n",
      "           Conv2d-79            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-81            [-1, 256, 8, 8]               0\n",
      "        AvgPool2d-82            [-1, 256, 1, 1]               0\n",
      "           Linear-83                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,919,626\n",
      "Trainable params: 4,919,626\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.63\n",
      "Params size (MB): 18.77\n",
      "Estimated Total Size (MB): 45.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e4d005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:01.163367Z",
     "iopub.status.busy": "2025-03-11T17:13:01.163144Z",
     "iopub.status.idle": "2025-03-11T17:13:01.167382Z",
     "shell.execute_reply": "2025-03-11T17:13:01.166631Z"
    },
    "papermill": {
     "duration": 0.010842,
     "end_time": "2025-03-11T17:13:01.168503",
     "exception": false,
     "start_time": "2025-03-11T17:13:01.157661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-c40c55aa8fd1>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Store training history\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "epoch_list = []\n",
    "\n",
    "# Initialize best loss and accuracy tracking\n",
    "best_loss = float(\"inf\")\n",
    "best_accuracy = 0.0\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d78b106f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:13:01.178999Z",
     "iopub.status.busy": "2025-03-11T17:13:01.178782Z",
     "iopub.status.idle": "2025-03-11T19:02:24.902512Z",
     "shell.execute_reply": "2025-03-11T19:02:24.901396Z"
    },
    "papermill": {
     "duration": 6563.740656,
     "end_time": "2025-03-11T19:02:24.914028",
     "exception": false,
     "start_time": "2025-03-11T17:13:01.173372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-4e9f2744558a>:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model at epoch 0 with val loss 1.3467 and accuracy 51.34%\n",
      "Epoch 0, Train loss 1.8080, Train Accuracy 35.25%, Test loss 1.3467, Test Accuracy 51.34%\n",
      "Saved best model at epoch 1 with val loss 1.1176 and accuracy 60.55%\n",
      "Epoch 1, Train loss 1.5074, Train Accuracy 48.40%, Test loss 1.1176, Test Accuracy 60.55%\n",
      "Saved best model at epoch 2 with val loss 0.9534 and accuracy 65.79%\n",
      "Epoch 2, Train loss 1.3512, Train Accuracy 55.30%, Test loss 0.9534, Test Accuracy 65.79%\n",
      "Saved best model at epoch 3 with val loss 0.8120 and accuracy 72.28%\n",
      "Epoch 3, Train loss 1.2930, Train Accuracy 57.97%, Test loss 0.8120, Test Accuracy 72.28%\n",
      "Epoch 4, Train loss 1.1931, Train Accuracy 61.76%, Test loss 0.9321, Test Accuracy 67.02%\n",
      "Saved best model at epoch 5 with val loss 0.7437 and accuracy 74.38%\n",
      "Epoch 5, Train loss 1.1789, Train Accuracy 62.82%, Test loss 0.7437, Test Accuracy 74.38%\n",
      "Epoch 6, Train loss 1.0710, Train Accuracy 66.60%, Test loss 0.8411, Test Accuracy 71.90%\n",
      "Saved best model at epoch 7 with val loss 0.6969 and accuracy 75.94%\n",
      "Epoch 7, Train loss 1.0705, Train Accuracy 67.12%, Test loss 0.6969, Test Accuracy 75.94%\n",
      "Saved best model at epoch 8 with val loss 0.6315 and accuracy 78.47%\n",
      "Epoch 8, Train loss 1.0312, Train Accuracy 68.85%, Test loss 0.6315, Test Accuracy 78.47%\n",
      "Saved best model at epoch 9 with val loss 0.5108 and accuracy 82.92%\n",
      "Epoch 9, Train loss 0.9766, Train Accuracy 70.50%, Test loss 0.5108, Test Accuracy 82.92%\n",
      "Saved best model at epoch 10 with val loss 0.4938 and accuracy 83.71%\n",
      "Epoch 10, Train loss 0.9716, Train Accuracy 70.64%, Test loss 0.4938, Test Accuracy 83.71%\n",
      "Saved best model at epoch 11 with val loss 0.4685 and accuracy 84.26%\n",
      "Epoch 11, Train loss 0.9315, Train Accuracy 72.31%, Test loss 0.4685, Test Accuracy 84.26%\n",
      "Saved best model at epoch 12 with val loss 0.4584 and accuracy 84.37%\n",
      "Epoch 12, Train loss 0.9215, Train Accuracy 72.74%, Test loss 0.4584, Test Accuracy 84.37%\n",
      "Epoch 13, Train loss 0.8995, Train Accuracy 73.01%, Test loss 0.4656, Test Accuracy 84.32%\n",
      "Saved best model at epoch 14 with val loss 0.4425 and accuracy 85.57%\n",
      "Epoch 14, Train loss 0.8689, Train Accuracy 74.25%, Test loss 0.4425, Test Accuracy 85.57%\n",
      "Saved best model at epoch 15 with val loss 0.4110 and accuracy 86.74%\n",
      "Epoch 15, Train loss 0.8594, Train Accuracy 74.41%, Test loss 0.4110, Test Accuracy 86.74%\n",
      "Epoch 16, Train loss 0.8461, Train Accuracy 75.27%, Test loss 0.4119, Test Accuracy 86.59%\n",
      "Saved best model at epoch 17 with val loss 0.3757 and accuracy 87.51%\n",
      "Epoch 17, Train loss 0.8232, Train Accuracy 75.85%, Test loss 0.3757, Test Accuracy 87.51%\n",
      "Epoch 18, Train loss 0.8151, Train Accuracy 76.10%, Test loss 0.3934, Test Accuracy 86.75%\n",
      "Saved best model at epoch 19 with val loss 0.3741 and accuracy 88.55%\n",
      "Epoch 19, Train loss 0.7720, Train Accuracy 77.38%, Test loss 0.3741, Test Accuracy 88.55%\n",
      "Epoch 20, Train loss 0.7939, Train Accuracy 77.09%, Test loss 0.3801, Test Accuracy 87.10%\n",
      "Epoch 21, Train loss 0.7398, Train Accuracy 78.34%, Test loss 0.3937, Test Accuracy 88.05%\n",
      "Saved best model at epoch 22 with val loss 0.3259 and accuracy 88.99%\n",
      "Epoch 22, Train loss 0.7584, Train Accuracy 78.05%, Test loss 0.3259, Test Accuracy 88.99%\n",
      "Saved best model at epoch 23 with val loss 0.3292 and accuracy 89.43%\n",
      "Epoch 23, Train loss 0.7377, Train Accuracy 78.27%, Test loss 0.3292, Test Accuracy 89.43%\n",
      "Epoch 24, Train loss 0.7541, Train Accuracy 78.99%, Test loss 0.3454, Test Accuracy 88.68%\n",
      "Saved best model at epoch 25 with val loss 0.3093 and accuracy 89.75%\n",
      "Epoch 25, Train loss 0.7320, Train Accuracy 79.16%, Test loss 0.3093, Test Accuracy 89.75%\n",
      "Saved best model at epoch 26 with val loss 0.2871 and accuracy 90.67%\n",
      "Epoch 26, Train loss 0.6803, Train Accuracy 80.68%, Test loss 0.2871, Test Accuracy 90.67%\n",
      "Epoch 27, Train loss 0.7183, Train Accuracy 79.80%, Test loss 0.3041, Test Accuracy 90.51%\n",
      "Saved best model at epoch 28 with val loss 0.2905 and accuracy 90.85%\n",
      "Epoch 28, Train loss 0.6930, Train Accuracy 80.42%, Test loss 0.2905, Test Accuracy 90.85%\n",
      "Epoch 29, Train loss 0.7151, Train Accuracy 80.47%, Test loss 0.3135, Test Accuracy 90.10%\n",
      "Saved best model at epoch 30 with val loss 0.2609 and accuracy 91.51%\n",
      "Epoch 30, Train loss 0.6578, Train Accuracy 81.29%, Test loss 0.2609, Test Accuracy 91.51%\n",
      "Epoch 31, Train loss 0.7057, Train Accuracy 80.26%, Test loss 0.2620, Test Accuracy 91.35%\n",
      "Epoch 32, Train loss 0.6957, Train Accuracy 81.09%, Test loss 0.3268, Test Accuracy 90.45%\n",
      "Epoch 33, Train loss 0.6735, Train Accuracy 81.30%, Test loss 0.3068, Test Accuracy 90.33%\n",
      "Epoch 34, Train loss 0.6480, Train Accuracy 81.66%, Test loss 0.2849, Test Accuracy 90.72%\n",
      "Epoch 35, Train loss 0.6590, Train Accuracy 81.33%, Test loss 0.2773, Test Accuracy 90.90%\n",
      "Epoch 36, Train loss 0.6221, Train Accuracy 82.78%, Test loss 0.2666, Test Accuracy 91.39%\n",
      "Epoch 37, Train loss 0.6305, Train Accuracy 82.49%, Test loss 0.2712, Test Accuracy 91.41%\n",
      "Saved best model at epoch 38 with val loss 0.2663 and accuracy 91.87%\n",
      "Epoch 38, Train loss 0.6228, Train Accuracy 82.98%, Test loss 0.2663, Test Accuracy 91.87%\n",
      "Epoch 39, Train loss 0.6320, Train Accuracy 82.33%, Test loss 0.2713, Test Accuracy 91.44%\n",
      "Saved best model at epoch 40 with val loss 0.2442 and accuracy 92.14%\n",
      "Epoch 40, Train loss 0.6406, Train Accuracy 82.68%, Test loss 0.2442, Test Accuracy 92.14%\n",
      "Saved best model at epoch 41 with val loss 0.2414 and accuracy 92.12%\n",
      "Epoch 41, Train loss 0.6204, Train Accuracy 82.98%, Test loss 0.2414, Test Accuracy 92.12%\n",
      "Epoch 42, Train loss 0.5985, Train Accuracy 83.96%, Test loss 0.2664, Test Accuracy 91.58%\n",
      "Saved best model at epoch 43 with val loss 0.2457 and accuracy 92.46%\n",
      "Epoch 43, Train loss 0.6124, Train Accuracy 83.67%, Test loss 0.2457, Test Accuracy 92.46%\n",
      "Epoch 44, Train loss 0.6155, Train Accuracy 83.39%, Test loss 0.2720, Test Accuracy 91.98%\n",
      "Epoch 45, Train loss 0.6170, Train Accuracy 83.50%, Test loss 0.2461, Test Accuracy 92.09%\n",
      "Epoch 46, Train loss 0.5703, Train Accuracy 84.76%, Test loss 0.2617, Test Accuracy 92.40%\n",
      "Epoch 47, Train loss 0.5896, Train Accuracy 84.40%, Test loss 0.2580, Test Accuracy 91.99%\n",
      "Saved best model at epoch 48 with val loss 0.2225 and accuracy 92.78%\n",
      "Epoch 48, Train loss 0.6032, Train Accuracy 84.31%, Test loss 0.2225, Test Accuracy 92.78%\n",
      "Saved best model at epoch 49 with val loss 0.2108 and accuracy 93.01%\n",
      "Epoch 49, Train loss 0.5708, Train Accuracy 84.70%, Test loss 0.2108, Test Accuracy 93.01%\n",
      "Saved best model at epoch 50 with val loss 0.2174 and accuracy 93.19%\n",
      "Epoch 50, Train loss 0.5631, Train Accuracy 85.04%, Test loss 0.2174, Test Accuracy 93.19%\n",
      "Epoch 51, Train loss 0.5578, Train Accuracy 85.01%, Test loss 0.2203, Test Accuracy 93.10%\n",
      "Epoch 52, Train loss 0.5753, Train Accuracy 84.70%, Test loss 0.2286, Test Accuracy 92.95%\n",
      "Epoch 53, Train loss 0.5540, Train Accuracy 85.61%, Test loss 0.2188, Test Accuracy 92.57%\n",
      "Epoch 54, Train loss 0.5578, Train Accuracy 85.64%, Test loss 0.2219, Test Accuracy 92.85%\n",
      "Saved best model at epoch 55 with val loss 0.2162 and accuracy 93.27%\n",
      "Epoch 55, Train loss 0.5474, Train Accuracy 85.36%, Test loss 0.2162, Test Accuracy 93.27%\n",
      "Epoch 56, Train loss 0.5612, Train Accuracy 85.32%, Test loss 0.2483, Test Accuracy 92.90%\n",
      "Saved best model at epoch 57 with val loss 0.2219 and accuracy 93.37%\n",
      "Epoch 57, Train loss 0.5565, Train Accuracy 85.38%, Test loss 0.2219, Test Accuracy 93.37%\n",
      "Saved best model at epoch 58 with val loss 0.2184 and accuracy 93.13%\n",
      "Epoch 58, Train loss 0.5593, Train Accuracy 85.18%, Test loss 0.2184, Test Accuracy 93.13%\n",
      "Epoch 59, Train loss 0.5177, Train Accuracy 86.45%, Test loss 0.2225, Test Accuracy 92.92%\n",
      "Saved best model at epoch 60 with val loss 0.2086 and accuracy 93.28%\n",
      "Epoch 60, Train loss 0.5302, Train Accuracy 86.18%, Test loss 0.2086, Test Accuracy 93.28%\n",
      "Saved best model at epoch 61 with val loss 0.1962 and accuracy 93.65%\n",
      "Epoch 61, Train loss 0.5008, Train Accuracy 86.85%, Test loss 0.1962, Test Accuracy 93.65%\n",
      "Epoch 62, Train loss 0.5359, Train Accuracy 86.29%, Test loss 0.2303, Test Accuracy 93.00%\n",
      "Epoch 63, Train loss 0.5173, Train Accuracy 86.68%, Test loss 0.2097, Test Accuracy 93.60%\n",
      "Epoch 64, Train loss 0.5460, Train Accuracy 85.93%, Test loss 0.2044, Test Accuracy 93.62%\n",
      "Saved best model at epoch 65 with val loss 0.2013 and accuracy 93.78%\n",
      "Epoch 65, Train loss 0.5397, Train Accuracy 86.47%, Test loss 0.2013, Test Accuracy 93.78%\n",
      "Epoch 66, Train loss 0.5189, Train Accuracy 86.56%, Test loss 0.2140, Test Accuracy 93.56%\n",
      "Epoch 67, Train loss 0.5117, Train Accuracy 86.53%, Test loss 0.2229, Test Accuracy 93.51%\n",
      "Saved best model at epoch 68 with val loss 0.1913 and accuracy 93.94%\n",
      "Epoch 68, Train loss 0.4900, Train Accuracy 87.81%, Test loss 0.1913, Test Accuracy 93.94%\n",
      "Epoch 69, Train loss 0.5318, Train Accuracy 86.81%, Test loss 0.2184, Test Accuracy 93.74%\n",
      "Epoch 70, Train loss 0.5330, Train Accuracy 86.27%, Test loss 0.1962, Test Accuracy 93.85%\n",
      "Epoch 71, Train loss 0.5141, Train Accuracy 86.80%, Test loss 0.2127, Test Accuracy 93.51%\n",
      "Saved best model at epoch 72 with val loss 0.2007 and accuracy 93.96%\n",
      "Epoch 72, Train loss 0.4990, Train Accuracy 87.19%, Test loss 0.2007, Test Accuracy 93.96%\n",
      "Saved best model at epoch 73 with val loss 0.1843 and accuracy 94.01%\n",
      "Epoch 73, Train loss 0.4911, Train Accuracy 87.92%, Test loss 0.1843, Test Accuracy 94.01%\n",
      "Saved best model at epoch 74 with val loss 0.1943 and accuracy 94.17%\n",
      "Epoch 74, Train loss 0.4875, Train Accuracy 87.65%, Test loss 0.1943, Test Accuracy 94.17%\n",
      "Epoch 75, Train loss 0.4743, Train Accuracy 88.34%, Test loss 0.1985, Test Accuracy 93.83%\n",
      "Saved best model at epoch 76 with val loss 0.1979 and accuracy 94.37%\n",
      "Epoch 76, Train loss 0.4908, Train Accuracy 87.86%, Test loss 0.1979, Test Accuracy 94.37%\n",
      "Saved best model at epoch 77 with val loss 0.1831 and accuracy 93.99%\n",
      "Epoch 77, Train loss 0.5095, Train Accuracy 87.73%, Test loss 0.1831, Test Accuracy 93.99%\n",
      "Saved best model at epoch 78 with val loss 0.1855 and accuracy 94.16%\n",
      "Epoch 78, Train loss 0.4875, Train Accuracy 88.07%, Test loss 0.1855, Test Accuracy 94.16%\n",
      "Epoch 79, Train loss 0.4864, Train Accuracy 88.08%, Test loss 0.1947, Test Accuracy 93.96%\n",
      "Saved best model at epoch 80 with val loss 0.1916 and accuracy 94.31%\n",
      "Epoch 80, Train loss 0.5013, Train Accuracy 87.90%, Test loss 0.1916, Test Accuracy 94.31%\n",
      "Saved best model at epoch 81 with val loss 0.1846 and accuracy 94.14%\n",
      "Epoch 81, Train loss 0.4722, Train Accuracy 88.92%, Test loss 0.1846, Test Accuracy 94.14%\n",
      "Saved best model at epoch 82 with val loss 0.1745 and accuracy 94.46%\n",
      "Epoch 82, Train loss 0.4714, Train Accuracy 88.61%, Test loss 0.1745, Test Accuracy 94.46%\n",
      "Epoch 83, Train loss 0.4476, Train Accuracy 88.91%, Test loss 0.1864, Test Accuracy 94.37%\n",
      "Epoch 84, Train loss 0.4424, Train Accuracy 89.29%, Test loss 0.1795, Test Accuracy 94.28%\n",
      "Epoch 85, Train loss 0.4602, Train Accuracy 88.64%, Test loss 0.2059, Test Accuracy 94.44%\n",
      "Epoch 86, Train loss 0.4702, Train Accuracy 88.56%, Test loss 0.2006, Test Accuracy 94.41%\n",
      "Saved best model at epoch 87 with val loss 0.1970 and accuracy 94.50%\n",
      "Epoch 87, Train loss 0.4448, Train Accuracy 89.48%, Test loss 0.1970, Test Accuracy 94.50%\n",
      "Saved best model at epoch 88 with val loss 0.1824 and accuracy 94.40%\n",
      "Epoch 88, Train loss 0.4482, Train Accuracy 88.91%, Test loss 0.1824, Test Accuracy 94.40%\n",
      "Saved best model at epoch 89 with val loss 0.1744 and accuracy 94.51%\n",
      "Epoch 89, Train loss 0.4512, Train Accuracy 88.86%, Test loss 0.1744, Test Accuracy 94.51%\n",
      "Saved best model at epoch 90 with val loss 0.1802 and accuracy 94.60%\n",
      "Epoch 90, Train loss 0.4221, Train Accuracy 90.18%, Test loss 0.1802, Test Accuracy 94.60%\n",
      "Saved best model at epoch 91 with val loss 0.1748 and accuracy 94.52%\n",
      "Epoch 91, Train loss 0.4431, Train Accuracy 89.76%, Test loss 0.1748, Test Accuracy 94.52%\n",
      "Saved best model at epoch 92 with val loss 0.1744 and accuracy 94.56%\n",
      "Epoch 92, Train loss 0.4681, Train Accuracy 89.10%, Test loss 0.1744, Test Accuracy 94.56%\n",
      "Saved best model at epoch 93 with val loss 0.1712 and accuracy 94.67%\n",
      "Epoch 93, Train loss 0.4292, Train Accuracy 89.85%, Test loss 0.1712, Test Accuracy 94.67%\n",
      "Saved best model at epoch 94 with val loss 0.1727 and accuracy 94.83%\n",
      "Epoch 94, Train loss 0.4598, Train Accuracy 88.97%, Test loss 0.1727, Test Accuracy 94.83%\n",
      "Epoch 95, Train loss 0.4171, Train Accuracy 90.33%, Test loss 0.1808, Test Accuracy 94.46%\n",
      "Epoch 96, Train loss 0.4078, Train Accuracy 90.43%, Test loss 0.1731, Test Accuracy 94.72%\n",
      "Epoch 97, Train loss 0.4224, Train Accuracy 90.42%, Test loss 0.1740, Test Accuracy 94.61%\n",
      "Saved best model at epoch 98 with val loss 0.1727 and accuracy 94.68%\n",
      "Epoch 98, Train loss 0.4287, Train Accuracy 90.29%, Test loss 0.1727, Test Accuracy 94.68%\n",
      "Saved best model at epoch 99 with val loss 0.1876 and accuracy 94.72%\n",
      "Epoch 99, Train loss 0.4263, Train Accuracy 90.09%, Test loss 0.1876, Test Accuracy 94.72%\n",
      "Saved best model at epoch 100 with val loss 0.1826 and accuracy 94.63%\n",
      "Epoch 100, Train loss 0.4325, Train Accuracy 90.05%, Test loss 0.1826, Test Accuracy 94.63%\n",
      "Saved best model at epoch 101 with val loss 0.1892 and accuracy 94.67%\n",
      "Epoch 101, Train loss 0.4480, Train Accuracy 89.69%, Test loss 0.1892, Test Accuracy 94.67%\n",
      "Saved best model at epoch 102 with val loss 0.1783 and accuracy 94.68%\n",
      "Epoch 102, Train loss 0.4455, Train Accuracy 89.24%, Test loss 0.1783, Test Accuracy 94.68%\n",
      "Saved best model at epoch 103 with val loss 0.1724 and accuracy 94.92%\n",
      "Epoch 103, Train loss 0.3959, Train Accuracy 90.97%, Test loss 0.1724, Test Accuracy 94.92%\n",
      "Saved best model at epoch 104 with val loss 0.1700 and accuracy 94.88%\n",
      "Epoch 104, Train loss 0.3723, Train Accuracy 91.28%, Test loss 0.1700, Test Accuracy 94.88%\n",
      "Epoch 105, Train loss 0.4113, Train Accuracy 90.60%, Test loss 0.1860, Test Accuracy 94.87%\n",
      "Saved best model at epoch 106 with val loss 0.1682 and accuracy 94.97%\n",
      "Epoch 106, Train loss 0.4066, Train Accuracy 90.65%, Test loss 0.1682, Test Accuracy 94.97%\n",
      "Epoch 107, Train loss 0.4256, Train Accuracy 90.27%, Test loss 0.1763, Test Accuracy 94.88%\n",
      "Epoch 108, Train loss 0.4272, Train Accuracy 90.50%, Test loss 0.1773, Test Accuracy 94.94%\n",
      "Epoch 109, Train loss 0.4440, Train Accuracy 90.12%, Test loss 0.1765, Test Accuracy 94.84%\n",
      "Epoch 110, Train loss 0.4419, Train Accuracy 89.87%, Test loss 0.1689, Test Accuracy 94.81%\n",
      "Epoch 111, Train loss 0.4180, Train Accuracy 90.85%, Test loss 0.1735, Test Accuracy 94.94%\n",
      "Epoch 112, Train loss 0.3920, Train Accuracy 90.86%, Test loss 0.1889, Test Accuracy 94.92%\n",
      "Epoch 113, Train loss 0.3947, Train Accuracy 91.41%, Test loss 0.1726, Test Accuracy 94.91%\n",
      "Epoch 114, Train loss 0.4535, Train Accuracy 89.74%, Test loss 0.1912, Test Accuracy 94.92%\n",
      "Epoch 115, Train loss 0.4150, Train Accuracy 90.62%, Test loss 0.1751, Test Accuracy 94.85%\n",
      "Saved best model at epoch 116 with val loss 0.1707 and accuracy 95.03%\n",
      "Epoch 116, Train loss 0.4179, Train Accuracy 90.48%, Test loss 0.1707, Test Accuracy 95.03%\n",
      "Epoch 117, Train loss 0.4538, Train Accuracy 89.46%, Test loss 0.1733, Test Accuracy 94.93%\n",
      "Saved best model at epoch 118 with val loss 0.1677 and accuracy 94.95%\n",
      "Epoch 118, Train loss 0.4067, Train Accuracy 90.36%, Test loss 0.1677, Test Accuracy 94.95%\n",
      "Saved best model at epoch 119 with val loss 0.1645 and accuracy 95.04%\n",
      "Epoch 119, Train loss 0.4485, Train Accuracy 90.20%, Test loss 0.1645, Test Accuracy 95.04%\n",
      "Epoch 120, Train loss 0.3814, Train Accuracy 91.26%, Test loss 0.1856, Test Accuracy 94.85%\n",
      "Epoch 121, Train loss 0.4002, Train Accuracy 90.70%, Test loss 0.1916, Test Accuracy 94.81%\n",
      "Epoch 122, Train loss 0.3870, Train Accuracy 90.90%, Test loss 0.1665, Test Accuracy 95.04%\n",
      "Epoch 123, Train loss 0.4247, Train Accuracy 90.00%, Test loss 0.1942, Test Accuracy 94.92%\n",
      "Epoch 124, Train loss 0.4128, Train Accuracy 90.49%, Test loss 0.1702, Test Accuracy 95.02%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predicted_output = model(images)\n",
    "            fit = loss(predicted_output, labels)  # Compute loss\n",
    "        \n",
    "        scaler.scale(fit).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += fit.item()\n",
    "        \n",
    "        # Compute training accuracy\n",
    "        if labels.dim() == 2:  # If labels are one-hot encoded (MixUp or CutMix)\n",
    "            labels = labels.argmax(dim=1)  # Convert to class indices\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = predicted_output.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted_output = model(images)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            predicted = F.softmax(predicted_output, dim=1)\n",
    "            _, predicted = predicted.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            fit = loss(predicted_output, labels)\n",
    "            test_loss += fit.item()\n",
    "\n",
    "    # Compute accuracy\n",
    "    train_accuracy = 100. * train_correct / train_total\n",
    "    test_accuracy = 100. * correct / total\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # Step the scheduler after validation\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save best model based on loss & accuracy\n",
    "    if best_loss > test_loss or best_accuracy < test_accuracy:\n",
    "        best_loss = test_loss\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"Saved best model at epoch {epoch} with val loss {best_loss:.4f} and accuracy {best_accuracy:.2f}%\")\n",
    "        \n",
    "    # Store loss and accuracy history\n",
    "    train_loss_history.append(train_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch}, Train loss {train_loss:.4f}, Train Accuracy {train_accuracy:.2f}%, Test loss {test_loss:.4f}, Test Accuracy {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55199f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:02:24.936481Z",
     "iopub.status.busy": "2025-03-11T19:02:24.936194Z",
     "iopub.status.idle": "2025-03-11T19:02:24.943029Z",
     "shell.execute_reply": "2025-03-11T19:02:24.942436Z"
    },
    "papermill": {
     "duration": 0.019276,
     "end_time": "2025-03-11T19:02:24.944157",
     "exception": false,
     "start_time": "2025-03-11T19:02:24.924881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save training history to Excel\n",
    "history_df = pd.DataFrame({\n",
    "    'Epoch': epoch,\n",
    "    'Train Loss': train_loss_history,\n",
    "    'Test Loss': test_loss_history,\n",
    "    'Train Accuracy': train_accuracy_history,\n",
    "    'Test Accuracy': test_accuracy_history\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36432707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:02:24.965443Z",
     "iopub.status.busy": "2025-03-11T19:02:24.965244Z",
     "iopub.status.idle": "2025-03-11T19:02:25.491501Z",
     "shell.execute_reply": "2025-03-11T19:02:25.490663Z"
    },
    "papermill": {
     "duration": 0.538459,
     "end_time": "2025-03-11T19:02:25.492864",
     "exception": false,
     "start_time": "2025-03-11T19:02:24.954405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to training_history.xlsx\n"
     ]
    }
   ],
   "source": [
    "history_df.to_excel(\"training_history.xlsx\", index=False)\n",
    "print(\"Training history saved to training_history.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b0980",
   "metadata": {
    "papermill": {
     "duration": 0.010095,
     "end_time": "2025-03-11T19:02:25.513578",
     "exception": false,
     "start_time": "2025-03-11T19:02:25.503483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6579.866927,
   "end_time": "2025-03-11T19:02:27.252520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T17:12:47.385593",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
